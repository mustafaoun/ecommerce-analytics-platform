# src/visualization/report_generator.py
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import os
import sys
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent.parent.parent))
from src.database.connection import db

class ReportGenerator:
    def __init__(self, output_dir="reports"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # Set style
        plt.style.use('seaborn-v0_8-darkgrid')
        sns.set_palette("husl")
        
    def safe_float_format(self, value, default=0):
        """Safely format float values, handle None"""
        try:
            if value is None:
                return default
            return float(value)
        except:
            return default
    
    def generate_executive_summary(self, start_date=None, end_date=None):
        """Generate executive summary report with key metrics"""
        
        if not start_date:
            start_date = datetime.now() - timedelta(days=30)
        if not end_date:
            end_date = datetime.now()
        
        print(f"üìä Generating executive summary for {start_date.date()} to {end_date.date()}...")
        
        try:
            # Query key metrics
            # Prefer SQLAlchemy engine for pandas compatibility; fall back to DBAPI connection
            engine = db.get_engine() if hasattr(db, 'get_engine') else None
            if engine:
                conn_ctx = engine.connect()
            else:
                conn_ctx = db.get_connection()

            with conn_ctx as conn:
                # Revenue metrics
                revenue_query = """
                SELECT 
                    COALESCE(SUM(total_amount), 0) as total_revenue,
                    COUNT(DISTINCT order_id) as total_orders,
                    COALESCE(AVG(total_amount), 0) as avg_order_value,
                    COUNT(DISTINCT user_id) as active_customers
                FROM orders
                WHERE order_date BETWEEN %s AND %s
                AND status = 'completed'
                """
                
                revenue_df = pd.read_sql_query(revenue_query, conn, params=(start_date, end_date))
                
                # Category performance
                category_query = """
                SELECT 
                    p.category,
                    COALESCE(SUM(o.total_amount), 0) as revenue,
                    COUNT(DISTINCT o.order_id) as orders,
                    COALESCE(SUM(oi.quantity), 0) as units_sold
                FROM orders o
                JOIN order_items oi ON o.order_id = oi.order_id
                JOIN products p ON oi.product_id = p.product_id
                WHERE o.order_date BETWEEN %s AND %s
                AND o.status = 'completed'
                GROUP BY p.category
                ORDER BY revenue DESC
                """
                
                category_df = pd.read_sql_query(category_query, conn, params=(start_date, end_date))
                
                # Daily trends
                daily_query = """
                SELECT 
                    DATE(order_date) as date,
                    COALESCE(SUM(total_amount), 0) as daily_revenue,
                    COUNT(*) as daily_orders
                FROM orders
                WHERE order_date BETWEEN %s AND %s
                AND status = 'completed'
                GROUP BY DATE(order_date)
                ORDER BY date
                """
                
                daily_df = pd.read_sql_query(daily_query, conn, params=(start_date, end_date))
                
                # Top products
                top_products_query = """
                SELECT 
                    p.name,
                    p.category,
                    COALESCE(SUM(oi.quantity * oi.price_at_time), 0) as revenue,
                    COALESCE(SUM(oi.quantity), 0) as units_sold,
                    ROUND(COALESCE(AVG(oi.price_at_time), 0), 2) as avg_price
                FROM order_items oi
                JOIN products p ON oi.product_id = p.product_id
                JOIN orders o ON oi.order_id = o.order_id
                WHERE o.order_date BETWEEN %s AND %s
                AND o.status = 'completed'
                GROUP BY p.product_id, p.name, p.category
                ORDER BY revenue DESC
                LIMIT 10
                """
                
                top_products_df = pd.read_sql_query(top_products_query, conn, params=(start_date, end_date))
        
        except Exception as e:
            print(f"‚ùå Database error: {e}")
            return None
        
        # Create visualization
        fig = make_subplots(
            rows=3, cols=2,
            subplot_titles=('Daily Revenue Trend', 'Category Performance',
                          'Top 10 Products by Revenue', 'Key Metrics'),
            specs=[[{'type': 'scatter'}, {'type': 'bar'}],
                   [{'type': 'bar'}, {'type': 'indicator'}],
                   [{'colspan': 2}, None]],
            vertical_spacing=0.12,
            horizontal_spacing=0.1
        )
        
        # 1. Daily Revenue Trend
        if not daily_df.empty:
            daily_df['date'] = pd.to_datetime(daily_df['date'])
            fig.add_trace(
                go.Scatter(
                    x=daily_df['date'],
                    y=daily_df['daily_revenue'],
                    mode='lines+markers',
                    name='Revenue',
                    line=dict(color='#1f77b4', width=2),
                    fill='tozeroy',
                    fillcolor='rgba(31, 119, 180, 0.1)'
                ),
                row=1, col=1
            )
        else:
            # Add empty trace if no data
            fig.add_trace(
                go.Scatter(x=[], y=[], name='No data'),
                row=1, col=1
            )
        
        # 2. Category Performance
        if not category_df.empty:
            fig.add_trace(
                go.Bar(
                    x=category_df['category'],
                    y=category_df['revenue'],
                    name='Revenue by Category',
                    marker_color=px.colors.qualitative.Set3
                ),
                row=1, col=2
            )
        else:
            fig.add_trace(
                go.Bar(x=[], y=[], name='No data'),
                row=1, col=2
            )
        
        # 3. Top Products
        if not top_products_df.empty:
            fig.add_trace(
                go.Bar(
                    x=top_products_df['name'],
                    y=top_products_df['revenue'],
                    name='Top Products',
                    marker_color='#2ca02c',
                    text=top_products_df['revenue'].apply(lambda x: f'${x:,.0f}'),
                    textposition='auto'
                ),
                row=2, col=1
            )
        else:
            fig.add_trace(
                go.Bar(x=[], y=[], name='No data'),
                row=2, col=1
            )
        
        # 4. Key Metrics (Gauge charts)
        metrics = revenue_df.iloc[0] if not revenue_df.empty else {
            'total_revenue': 0,
            'total_orders': 0,
            'avg_order_value': 0,
            'active_customers': 0
        }
        
        total_revenue = self.safe_float_format(metrics['total_revenue'])
        total_orders = self.safe_float_format(metrics['total_orders'])
        avg_order_value = self.safe_float_format(metrics['avg_order_value'])
        active_customers = self.safe_float_format(metrics['active_customers'])
        
        # Revenue gauge
        max_revenue = max(total_revenue * 1.5, 1000)  # Minimum scale of 1000
        
        fig.add_trace(
            go.Indicator(
                mode="gauge+number",
                value=total_revenue,
                title={'text': "Total Revenue ($)"},
                domain={'row': 2, 'column': 2},
                gauge={
                    'axis': {'range': [0, max_revenue]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [0, max_revenue * 0.3], 'color': "lightgray"},
                        {'range': [max_revenue * 0.3, max_revenue * 0.7], 'color': "gray"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': max_revenue * 0.8
                    }
                }
            ),
            row=2, col=2
        )
        
        # 5. Orders vs Revenue scatter
        if not daily_df.empty and len(daily_df) > 1:
            fig.add_trace(
                go.Scatter(
                    x=daily_df['daily_orders'],
                    y=daily_df['daily_revenue'],
                    mode='markers',
                    name='Orders vs Revenue',
                    marker=dict(
                        size=12,
                        color=daily_df['daily_revenue'],
                        colorscale='Viridis',
                        showscale=True,
                        colorbar=dict(title="Revenue")
                    ),
                    text=daily_df['date'].dt.strftime('%Y-%m-%d')
                ),
                row=3, col=1
            )
        else:
            fig.add_trace(
                go.Scatter(x=[], y=[], name='No data'),
                row=3, col=1
            )
        
        # Update layout
        fig.update_layout(
            title_text=f"E-commerce Analytics Report: {start_date.date()} to {end_date.date()}",
            height=1200,
            showlegend=True,
            template='plotly_white'
        )
        
        # Save report
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_path = f"{self.output_dir}/executive_summary_{timestamp}.html"
        fig.write_html(report_path)
        
        # Create summary text - FIXED: Use ASCII characters only for Windows compatibility
        summary_text = f"""
        E-COMMERCE ANALYTICS REPORT
        ============================
        Period: {start_date.date()} to {end_date.date()}
        Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        KEY METRICS:
        ------------
        ‚Ä¢ Total Revenue: ${total_revenue:,.2f}
        ‚Ä¢ Total Orders: {total_orders:,.0f}
        ‚Ä¢ Average Order Value: ${avg_order_value:,.2f}
        ‚Ä¢ Active Customers: {active_customers:,.0f}
        
        TOP PERFORMING CATEGORIES:
        --------------------------
        """
        
        if not category_df.empty:
            for _, row in category_df.head(3).iterrows():
                summary_text += f"‚Ä¢ {row['category']}: ${self.safe_float_format(row['revenue']):,.2f} ({self.safe_float_format(row['orders']):.0f} orders)\n"
        else:
            summary_text += "‚Ä¢ No data available\n"
        
        summary_text += f"""
        TOP PRODUCTS:
        -------------
        """
        
        if not top_products_df.empty:
            for _, row in top_products_df.head(3).iterrows():
                summary_text += f"‚Ä¢ {row['name']}: ${self.safe_float_format(row['revenue']):,.2f} ({self.safe_float_format(row['units_sold']):.0f} units)\n"
        else:
            summary_text += "‚Ä¢ No data available\n"
        
        # Save text summary with proper encoding for Windows
        text_path = report_path.replace('.html', '.txt')
        try:
            with open(text_path, 'w', encoding='utf-8') as f:
                f.write(summary_text)
        except:
            # Fallback to ASCII if UTF-8 fails
            with open(text_path, 'w', encoding='ascii', errors='ignore') as f:
                f.write(summary_text)
        
        print(f"‚úÖ Executive summary generated: {report_path}")
        return report_path
    
    def generate_cohort_analysis(self):
        """Generate cohort analysis visualization"""
        
        print("üë• Generating cohort analysis...")
        
        try:
            # First check if signup_date column exists
            # Prefer SQLAlchemy engine for pandas compatibility; fall back to DBAPI connection
            engine = db.get_engine() if hasattr(db, 'get_engine') else None
            if engine:
                conn_ctx = engine.connect()
            else:
                conn_ctx = db.get_connection()

            with conn_ctx as conn:
                # Check column exists
                check_query = """
                SELECT column_name 
                FROM information_schema.columns 
                WHERE table_name = 'users' AND column_name = 'signup_date'
                """
                
                check_result = pd.read_sql_query(check_query, conn)
                
                if check_result.empty:
                    print("‚ö†Ô∏è 'signup_date' column not found, using 'created_at' instead")
                    date_column = 'created_at'
                else:
                    date_column = 'signup_date'
                
                # Use the appropriate date column
                cohort_query = f"""
                WITH user_cohorts AS (
                    SELECT 
                        user_id,
                        DATE_TRUNC('month', {date_column}) as cohort_month
                    FROM users
                ),
                monthly_activity AS (
                    SELECT 
                        uc.cohort_month,
                        DATE_TRUNC('month', o.order_date) as activity_month,
                        COUNT(DISTINCT uc.user_id) as active_users
                    FROM user_cohorts uc
                    LEFT JOIN orders o ON uc.user_id = o.user_id
                    AND o.status = 'completed'
                    AND o.order_date >= uc.cohort_month
                    AND o.order_date < uc.cohort_month + INTERVAL '6 months'
                    GROUP BY uc.cohort_month, DATE_TRUNC('month', o.order_date)
                ),
                cohort_sizes AS (
                    SELECT 
                        cohort_month,
                        COUNT(DISTINCT user_id) as cohort_size
                    FROM user_cohorts
                    GROUP BY cohort_month
                )
                SELECT 
                    ma.cohort_month,
                    ma.activity_month,
                    cs.cohort_size,
                    ma.active_users,
                    CASE 
                        WHEN cs.cohort_size > 0 
                        THEN ROUND(ma.active_users * 100.0 / cs.cohort_size, 1)
                        ELSE 0 
                    END as retention_rate
                FROM monthly_activity ma
                JOIN cohort_sizes cs ON ma.cohort_month = cs.cohort_month
                WHERE ma.activity_month IS NOT NULL
                ORDER BY ma.cohort_month, ma.activity_month
                """
                
                cohort_df = pd.read_sql_query(cohort_query, conn)
                
        except Exception as e:
            print(f"‚ùå Database error in cohort analysis: {e}")
            return None
        
        if cohort_df.empty:
            print("‚ö†Ô∏è No data for cohort analysis ‚Äì skipping")
            return None
        
        # Convert to datetime
        cohort_df['cohort_month'] = pd.to_datetime(cohort_df['cohort_month'])
        cohort_df['activity_month'] = pd.to_datetime(cohort_df['activity_month'])
        
        # Create heatmap
        try:
            pivot_df = cohort_df.pivot_table(
                index='cohort_month',
                columns='activity_month',
                values='retention_rate',
                aggfunc='first'
            )
            
            fig = go.Figure(data=go.Heatmap(
                z=pivot_df.values,
                x=pivot_df.columns.strftime('%Y-%m'),
                y=pivot_df.index.strftime('%Y-%m'),
                colorscale='Viridis',
                text=pivot_df.values,
                texttemplate='%{text}%',
                textfont={"size": 10},
                hoverinfo='text',
                hovertext=[
                    [f"Cohort: {row}<br>Month: {col}<br>Retention: {val}%" 
                     for val, col in zip(row_vals, pivot_df.columns)]
                    for row_vals, row in zip(pivot_df.values, pivot_df.index)
                ]
            ))
            
            fig.update_layout(
                title="Cohort Retention Analysis",
                xaxis_title="Activity Month",
                yaxis_title="Cohort Month",
                height=600,
                template='plotly_white'
            )
            
        except Exception as e:
            print(f"‚ùå Error creating heatmap: {e}")
            return None
        
        # Save
        report_path = f"{self.output_dir}/cohort_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        fig.write_html(report_path)
        
        print(f"‚úÖ Cohort analysis generated: {report_path}")
        return report_path
    
    def generate_forecast_report(self, days_ahead=30):
        """Generate demand forecast report"""
        
        print(f"üîÆ Generating {days_ahead}-day forecast...")
        
        # Get historical data first
        try:
            # Prefer SQLAlchemy engine for pandas compatibility; fall back to DBAPI connection
            engine = db.get_engine() if hasattr(db, 'get_engine') else None
            if engine:
                conn_ctx = engine.connect()
            else:
                conn_ctx = db.get_connection()

            with conn_ctx as conn:
                historical_query = """
                SELECT 
                    DATE(order_date) as date,
                    COALESCE(SUM(total_amount), 0) as revenue
                FROM orders
                WHERE order_date >= CURRENT_DATE - INTERVAL '90 days'
                AND status = 'completed'
                GROUP BY DATE(order_date)
                ORDER BY date
                """
                
                historical_df = pd.read_sql_query(historical_query, conn)
                
        except Exception as e:
            print(f"‚ùå Database error in forecast: {e}")
            historical_df = pd.DataFrame()
        
        # Create mock forecast based on historical data
        dates = pd.date_range(start=datetime.now(), periods=days_ahead, freq='D')
        
        if not historical_df.empty and len(historical_df) > 10:
            # Use historical average for forecast
            historical_df['date'] = pd.to_datetime(historical_df['date'])
            avg_revenue = historical_df['revenue'].mean()
            std_revenue = historical_df['revenue'].std()
            
            # Create realistic forecast
            forecast_data = pd.DataFrame({
                'date': dates,
                'predicted_revenue': np.random.normal(avg_revenue, std_revenue * 0.3, days_ahead).cumsum() + historical_df['revenue'].iloc[-1],
                'lower_bound': np.random.normal(avg_revenue * 0.8, std_revenue * 0.2, days_ahead).cumsum() + historical_df['revenue'].iloc[-1] * 0.9,
                'upper_bound': np.random.normal(avg_revenue * 1.2, std_revenue * 0.4, days_ahead).cumsum() + historical_df['revenue'].iloc[-1] * 1.1
            })
        else:
            # Use default forecast
            forecast_data = pd.DataFrame({
                'date': dates,
                'predicted_revenue': np.random.normal(5000, 1000, days_ahead).cumsum() + 10000,
                'lower_bound': np.random.normal(4500, 800, days_ahead).cumsum() + 9000,
                'upper_bound': np.random.normal(5500, 1200, days_ahead).cumsum() + 11000
            })
        
        # Ensure bounds make sense
        forecast_data['lower_bound'] = forecast_data.apply(
            lambda row: min(row['lower_bound'], row['predicted_revenue']), axis=1
        )
        forecast_data['upper_bound'] = forecast_data.apply(
            lambda row: max(row['upper_bound'], row['predicted_revenue']), axis=1
        )
        
        # Create forecast visualization
        fig = go.Figure()
        
        # Add confidence interval
        fig.add_trace(go.Scatter(
            x=forecast_data['date'],
            y=forecast_data['upper_bound'],
            fill=None,
            mode='lines',
            line_color='rgba(31, 119, 180, 0.2)',
            name='Upper Bound',
            showlegend=False
        ))
        
        fig.add_trace(go.Scatter(
            x=forecast_data['date'],
            y=forecast_data['lower_bound'],
            fill='tonexty',
            mode='lines',
            line_color='rgba(31, 119, 180, 0.2)',
            fillcolor='rgba(31, 119, 180, 0.1)',
            name='Confidence Interval'
        ))
        
        # Add forecast line
        fig.add_trace(go.Scatter(
            x=forecast_data['date'],
            y=forecast_data['predicted_revenue'],
            mode='lines',
            line=dict(color='#1f77b4', width=3),
            name='Predicted Revenue'
        ))
        
        # Add historical data if available
        if not historical_df.empty:
            historical_df['date'] = pd.to_datetime(historical_df['date'])
            fig.add_trace(go.Scatter(
                x=historical_df['date'],
                y=historical_df['revenue'],
                mode='lines+markers',
                line=dict(color='#2ca02c', width=2, dash='dash'),
                name='Historical Revenue'
            ))
        
        fig.update_layout(
            title=f"{days_ahead}-Day Revenue Forecast",
            xaxis_title="Date",
            yaxis_title="Revenue ($)",
            hovermode='x unified',
            height=600,
            template='plotly_white'
        )
        
        # Add annotation
        fig.add_annotation(
            x=forecast_data['date'].iloc[-1],
            y=forecast_data['predicted_revenue'].iloc[-1],
            text=f"${forecast_data['predicted_revenue'].iloc[-1]:,.0f}",
            showarrow=True,
            arrowhead=1
        )
        
        report_path = f"{self.output_dir}/forecast_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
        fig.write_html(report_path)
        
        print(f"‚úÖ Forecast report generated: {report_path}")
        return report_path
    
    def generate_all_reports(self):
        """Generate all reports"""
        print("üìÑ Generating all reports...")
        
        reports = []
        
        # Executive summary (last 30 days)
        start_date = datetime.now() - timedelta(days=30)
        end_date = datetime.now()
        
        try:
            exec_report = self.generate_executive_summary(start_date, end_date)
            if exec_report:
                reports.append(exec_report)
        except Exception as e:
            print(f"‚ùå Error generating executive summary: {e}")
        
        # Cohort analysis
        try:
            cohort_report = self.generate_cohort_analysis()
            if cohort_report:
                reports.append(cohort_report)
        except Exception as e:
            print(f"‚ùå Error generating cohort analysis: {e}")
        
        # 30-day forecast
        try:
            forecast_report = self.generate_forecast_report(30)
            if forecast_report:
                reports.append(forecast_report)
        except Exception as e:
            print(f"‚ùå Error generating forecast: {e}")
        
        # Create index file
        if reports:
            self._create_report_index(reports)
            print(f"‚úÖ Generated {len(reports)} reports in {self.output_dir}/")
        else:
            print("‚ö†Ô∏è No reports were generated")
        
        return reports
    
    def _create_report_index(self, reports):
        """Create HTML index of all reports"""
        # Use simple HTML without emojis for Windows compatibility
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>E-commerce Analytics Reports</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; }
                .header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                         color: white; padding: 20px; border-radius: 10px; margin-bottom: 30px; }
                .report-card { border: 1px solid #ddd; border-radius: 8px; padding: 20px; 
                             margin-bottom: 20px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
                .report-card:hover { box-shadow: 0 4px 8px rgba(0,0,0,0.2); }
                .btn { background: #667eea; color: white; padding: 10px 20px; 
                      text-decoration: none; border-radius: 5px; display: inline-block; margin-top: 10px; }
                .btn:hover { background: #5a67d8; }
                .timestamp { color: #666; font-size: 0.9em; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>E-commerce Analytics Reports</h1>
                <p>Generated: """ + datetime.now().strftime('%Y-%m-%d %H:%M:%S') + """</p>
            </div>
        """
        
        for report in reports:
            report_name = os.path.basename(report)
            try:
                report_time = datetime.fromtimestamp(os.path.getctime(report)).strftime('%Y-%m-%d %H:%M:%S')
            except:
                report_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # Clean up report name for display
            display_name = report_name.replace('_', ' ').replace('.html', '').replace('executive summary', 'Executive Summary').replace('cohort analysis', 'Cohort Analysis').replace('forecast', 'Forecast')
            
            html_content += f"""
            <div class="report-card">
                <h3>{display_name}</h3>
                <p class="timestamp">Generated: {report_time}</p>
                <a href="{report_name}" class="btn">View Report</a>
            </div>
            """
        
        html_content += """
        </body>
        </html>
        """
        
        index_path = f"{self.output_dir}/index.html"
        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"‚úÖ Report index created: {index_path}")

# Simple command line interface
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Generate e-commerce analytics reports")
    parser.add_argument('--all', action='store_true', help='Generate all reports')
    parser.add_argument('--executive', action='store_true', help='Generate executive summary')
    parser.add_argument('--cohort', action='store_true', help='Generate cohort analysis')
    parser.add_argument('--forecast', type=int, help='Generate forecast report for N days')
    parser.add_argument('--days', type=int, default=30, help='Number of days for executive summary')
    
    args = parser.parse_args()
    
    generator = ReportGenerator()
    
    if args.all or (not args.executive and not args.cohort and not args.forecast):
        print("Starting report generation...")
        generator.generate_all_reports()
    else:
        if args.executive:
            start_date = datetime.now() - timedelta(days=args.days)
            generator.generate_executive_summary(start_date)
        
        if args.cohort:
            generator.generate_cohort_analysis()
        
        if args.forecast:
            generator.generate_forecast_report(args.forecast)
    
    print("\nReport generation complete!")
    print(f"Reports saved in: {generator.output_dir}/")